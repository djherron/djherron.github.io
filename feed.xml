<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://djherron.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://djherron.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-08T08:04:15+00:00</updated><id>https://djherron.github.io/feed.xml</id><title type="html">blank</title><subtitle>My personal website. </subtitle><entry><title type="html">the Bellman equation for state values</title><link href="https://djherron.github.io/blog/2022/reinforcement-learning/" rel="alternate" type="text/html" title="the Bellman equation for state values"/><published>2022-12-12T15:30:00+00:00</published><updated>2022-12-12T15:30:00+00:00</updated><id>https://djherron.github.io/blog/2022/reinforcement-learning</id><content type="html" xml:base="https://djherron.github.io/blog/2022/reinforcement-learning/"><![CDATA[<p>In their book “Reinforcement Learning: An Introduction”, 2nd edition, 2018, Richard Sutton and Andrew Barto define the Bellman equation for state values in the following manner:</p> <blockquote> \[v_\pi(s) \doteq \mathbb{E}_\pi [G_t|S_t = s] = \sum_a \pi(a|s) \sum_{s^\prime} \sum_r p(s^\prime ,r|s,a) \Big[r + \gamma v_\pi(s^\prime)\Big] \qquad \forall \ s \in \mathcal{S}\] </blockquote> <p>Seeing how it is that the right-hand side of this fascinating, recursive Bellman equation arises from the expectation expression on the left-hand side requires some understanding of probability theory. Sutton &amp; Barto rightly focus on teaching reinforcement learning. Students of reinforcement learning are left to work out the probabilistic reasoning that gives rise to the Bellman equation for themselves.</p> <p>Attached is a PDF containing a <strong>derivation</strong> of the Bellman equation for state values that takes readers from the expectation expression on the left-hand side to the fascinating, recursive expression on the right-hand side. It was developed by me, for me, and for people like me — people with only a basic grasp of probability theory who want a detailed, step-by-step derivation with lots of supporting explanation. Sophisticated probability people will likely find this derivation verbose and tedious.</p> <h1 class="post-title"> <a href="/assets/pdf/Bellman_equation_derivation.pdf" target="_blank" rel="noopener noreferrer" class="float-left"><i class="fas fa-file-pdf"></i></a> </h1>]]></content><author><name></name></author><category term="probability"/><category term="reinforcement-learning"/><summary type="html"><![CDATA[a derivation]]></summary></entry></feed>